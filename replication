# ====================================
### Preliminaries
# ====================================

## Installing packages
install.packages(c("sf", "ggplot2", "cowplot", "tmap", "dplyr", "readr", 
                   "viridis", "spdep", "MatchIt", "spatialreg"))

## Loading required libraries
library(sf)
library(ggplot2)
library(tmap)
library(dplyr)
library(purrr)
library(fs)
library(readxl)
library(tidyr)
library(readr)

## Setting working directory
setwd("~/Desktop/My Data")

## Loading and combining shapefiles
lsoa_dir <- "~/Desktop/LB_shp/"
lsoa_shps <- dir_ls(lsoa_dir, regexp = "\\.shp$")

lsoa_sf <- map_dfr(lsoa_shps, ~ {
  shp <- st_read(.x, quiet = TRUE)
  st_transform(shp, 27700)
})

## Loading green space comparison
greenspace_comparison <- read_csv("~/Desktop/Greenspace_Comparison_2017_2024.csv") %>%
  mutate(lsoa21cd = as.character(lsoa21cd),
         area_km2 = total_area_sqm_2017 / 1e6)

## Loading crime data and join LSOA lookup
data_dir <- "~/Desktop/My Data/Crimes"
file_list <- list.files(path = data_dir, 
                        pattern = "-(metropolitan|city-of-london)-street\\.csv$", 
                        full.names = TRUE)

all_crime_data <- file_list %>%
  lapply(read.csv, stringsAsFactors = FALSE) %>%
  bind_rows()

lsoa_lookup <- read_csv("~/Desktop/My Data/LSOA_(2011)_to_LSOA_(2021)_to_Local_Authority_District_(2022)_Exact_Fit_Lookup_for_EW_(V3).csv") %>%
  select(LSOA11CD, LSOA21CD)

all_crime_data <- all_crime_data %>%
  rename(lsoa11cd = LSOA.code) %>%
  left_join(lsoa_lookup, by = c("lsoa11cd" = "LSOA11CD")) %>%
  select(-lsoa11cd) %>%
  rename(LSOA.code = LSOA21CD)

## Load Borough Geometry
boroughs <- st_read("~/Desktop/My Data/districts.shp") %>%
  st_transform(crs = 27700)

## Loading and processing population data (2011–2024)
sheets <- 11:16
years <- 2017:2022

load_population <- function(sheet, year) {
  read_excel("~/Desktop/My Data/sapelsoabroadage20112022.xlsx", sheet = sheet, skip = 3) %>%
    select(
      lsoa_code = `LSOA 2021 Code`,
      Total,
      `M16 to 29`
    ) %>%
    mutate(
      year = year,
      percent_male_youth = 100 * `M16 to 29` / Total
    )
}

population_all_years <- map2_dfr(sheets, years, load_population)

valid_lsoas <- unique(lsoa_sf$lsoa21cd)

population_filtered <- population_all_years %>%
  filter(lsoa_code %in% valid_lsoas)

## Projecting Population for 2023 and 2024
growth_df <- population_filtered %>%
  filter(year %in% c(2020, 2022)) %>%
  select(lsoa_code, year, Total) %>%
  pivot_wider(names_from = year, values_from = Total, names_prefix = "year_") %>%
  mutate(
    growth_rate = (year_2022 - year_2020) / 2,
    population_2023 = year_2022 + growth_rate,
    population_2024 = year_2022 + 2 * growth_rate
  ) %>%
  select(lsoa_code, population_2023, population_2024)

population_projected <- growth_df %>%
  pivot_longer(
    cols = starts_with("population_"), 
    names_to = "year", 
    names_prefix = "population_", 
    values_to = "Total"
  ) %>%
  mutate(
    year = as.integer(year),
    `M16 to 29` = NA_real_,
    percent_male_youth = NA_real_
  )

population_full <- bind_rows(
  population_filtered %>% select(lsoa_code, year, Total, `M16 to 29`, percent_male_youth),
  population_projected
)

population_full <- population_full %>%
  mutate(
    population = if ("Total" %in% colnames(.)) map_dbl(Total, as.numeric) else population
  )

## Subsets for 2017
male_youth_2017 <- population_full %>%
  filter(year == 2017) %>%
  select(lsoa_code, percent_male_youth)

pop_total_2017 <- population_full %>%
  filter(year == 2017) %>%
  select(lsoa_code, Total)

# Loading IMD and ethnicity datasets
imd_2019 <- read_excel("~/Desktop/My Data/ID 2019 for London.xlsx", sheet = 2) %>%
  select(
    LSOA_code = `LSOA code (2011)`,
    imd_score = `Index of Multiple Deprivation (IMD) Score`,
    imd_decile = `Index of Multiple Deprivation (IMD) Decile (where 1 is most deprived 10% of LSOAs)`,
    crime_score = `Crime Score`,
    env_score = `Living Environment Score`
  )

ethnicity_data <- read_excel("~/Desktop/My Data/Ethnic group.xlsx", sheet = 4) %>%
  rename(
    LSOA_code = `LSOA code`,
    white_british = `White British`,
    white_irish = `White Irish`,
    white_gypsy = `White Gypsy/Irish Traveller`,
    white_roma = `White Roma`,
    white_other = `White Other`,
    total_pop = `All usual residents`
  ) %>%
  mutate(
    percent_white = 100 * (white_british + white_irish + white_gypsy + white_roma + white_other) / total_pop,
    percent_nonwhite = 100 - percent_white
  ) %>%
  select(LSOA_code, percent_white, percent_nonwhite)

percent_nonwhite <- ethnicity_data %>%
  select(LSOA_code, percent_nonwhite)

## Merging data into green space data
greenspace_comparison <- greenspace_comparison %>%
  left_join(pop_total_2017, by = c("lsoa21cd" = "lsoa_code")) %>%
  mutate(pop_density_2017 = Total / area_km2) %>%
  left_join(imd_2019, by = c("lsoa21cd" = "LSOA_code")) %>%
  left_join(percent_nonwhite, by = c("lsoa21cd" = "LSOA_code"))

# Loading tree canopy and ward shapes
canopy_data <- read_excel("~/Downloads/London Canopy Cover Mapping - Ward Prioritisation Tool.xlsx", sheet = 2)

wards <- st_read("~/Desktop/London-wards-2018/London-wards-2018_ESRI/London_Ward.shp") %>%
  st_transform(27700)

# ====================================
### EXPLORATORY DATA ANALYSIS
# ====================================

## Calculating crime rate change (2017–2024)
# Filtering and summarising violent crime counts by LSOA and year
crime_summary <- all_crime_data %>%
  filter(Crime.type == "Violence and sexual offences") %>%
  mutate(Year = as.integer(substr(Month, 1, 4))) %>%
  filter(Year %in% c(2017, 2024)) %>%
  group_by(LSOA.code, Year) %>%
  summarise(total_crimes = n(), .groups = "drop") %>%
  pivot_wider(
    names_from = Year,
    values_from = total_crimes,
    names_prefix = "crime_"
  ) %>%
  mutate(across(starts_with("crime_"), ~replace_na(., 0)))

# Joining with population data for rate calculation
crime_diff_df <- crime_summary %>%
  left_join(pop_total_2017, by = c("LSOA.code" = "lsoa_code")) %>%
  left_join(
    population_full %>%
      filter(year == 2024) %>%
      select(lsoa_code, Total_2024 = Total),
    by = c("LSOA.code" = "lsoa_code")
  ) %>%
  mutate(
    rate_2017 = 1000 * crime_2017 / Total,
    rate_2024 = 1000 * crime_2024 / Total_2024,
    delta_rate = rate_2024 - rate_2017
  )

## Crime change summary statistics
summary_stats <- crime_diff_df %>%
  summarise(
    mean_crime_change = mean(delta_rate, na.rm = TRUE),
    sd_crime_change   = sd(delta_rate, na.rm = TRUE),
    min_crime_change  = min(delta_rate, na.rm = TRUE),
    max_crime_change  = max(delta_rate, na.rm = TRUE)
  )

summary_stats

## Green space change summary statistics
greenspace_summary <- greenspace_comparison %>%
  summarise(
    mean_green_change = mean(green_percent_2024 - green_percent_2017, na.rm = TRUE),
    sd_green_change   = sd(green_percent_2024 - green_percent_2017, na.rm = TRUE),
    min_green_change  = min(green_percent_2024 - green_percent_2017, na.rm = TRUE),
    max_green_change  = max(green_percent_2024 - green_percent_2017, na.rm = TRUE)
  )

greenspace_summary

## Loading required packages
library(sf)
library(dplyr)
library(spdep)
library(ggplot2)
library(tidyr)
library(patchwork)

# Joining greenspace data to LSOAs
greenspace_sf <- lsoa_sf %>%
  left_join(greenspace_comparison, by = c("lsoa21cd" = "lsoa21cd")) %>%
  mutate(
    green_change = green_percent_2024 - green_percent_2017,
    green_std = scale(green_change)[, 1]
  )

# Spatial weights and LISA for green space change
# Defining neighbors using queen contiguity
nb_queen <- poly2nb(greenspace_sf, queen = TRUE)
lw_queen <- nb2listw(nb_queen, style = "W", zero.policy = TRUE)

# Global Moran's I
moran_green <- moran.test(greenspace_sf$green_change, lw_queen, zero.policy = TRUE)
print(moran_green)

# Local Moran's I
lisa_green <- localmoran(greenspace_sf$green_change, lw_queen, zero.policy = TRUE)

# classifying local clusters
greenspace_sf <- greenspace_sf %>%
  mutate(
    local_I = lisa_green[, "Ii"],
    p_value = lisa_green[, "Pr(z != E(Ii))"],
    lag_green = lag.listw(lw_queen, green_std, zero.policy = TRUE),
    cluster_type = case_when(
      green_std >= 0 & lag_green >= 0 & p_value <= 0.05 ~ "High-High",
      green_std <= 0 & lag_green <= 0 & p_value <= 0.05 ~ "Low-Low",
      green_std >= 0 & lag_green <= 0 & p_value <= 0.05 ~ "High-Low",
      green_std <= 0 & lag_green >= 0 & p_value <= 0.05 ~ "Low-High",
      TRUE ~ "Not significant"
    )
  )

## Preparing spatial data for crime rate change
# Summarising violent crimes in 2017 and 2024
crime_summary <- all_crime_data %>%
  filter(Crime.type == "Violence and sexual offences") %>%
  mutate(Year = as.integer(substr(Month, 1, 4))) %>%
  filter(Year %in% c(2017, 2024)) %>%
  group_by(LSOA.code, Year) %>%
  summarise(total_crimes = n(), .groups = "drop") %>%
  pivot_wider(names_from = Year, values_from = total_crimes, names_prefix = "crime_") %>%
  mutate(across(starts_with("crime_"), ~replace_na(., 0)))

# Getting population for 2017 and 2024
pop_subset <- population_full %>%
  filter(year %in% c(2017, 2024)) %>%
  select(lsoa_code, year, Total) %>%
  pivot_wider(names_from = year, values_from = Total, names_prefix = "pop_")

# Joining crime, population, and geometry
crime_diff_sf <- lsoa_sf %>%
  select(lsoa21cd, geometry) %>%
  left_join(crime_summary, by = c("lsoa21cd" = "LSOA.code")) %>%
  left_join(pop_subset, by = c("lsoa21cd" = "lsoa_code")) %>%
  mutate(
    rate_2017 = 1000 * crime_2017 / pop_2017,
    rate_2024 = 1000 * crime_2024 / pop_2024,
    delta_rate = rate_2024 - rate_2017
  )

## Spatial weights and LISA for crime rate change
crime_clean <- crime_diff_sf %>%
  filter(!is.na(delta_rate)) %>%
  st_make_valid() %>%
  mutate(crime_std = scale(delta_rate)[, 1])

nb_crime <- poly2nb(crime_clean, queen = TRUE)
lw_crime <- nb2listw(nb_crime, style = "W", zero.policy = TRUE)

# Global Moran's I
moran_crime <- moran.test(crime_clean$delta_rate, lw_crime, zero.policy = TRUE)
print(moran_crime)

# Local Moran's I
lisa_crime <- localmoran(crime_clean$delta_rate, lw_crime, zero.policy = TRUE)

# Classifying local clusters
crime_clean <- crime_clean %>%
  mutate(
    local_I = lisa_crime[, "Ii"],
    p_value = lisa_crime[, "Pr(z != E(Ii))"],
    lag_crime = lag.listw(lw_crime, crime_std, zero.policy = TRUE),
    crime_cluster = case_when(
      crime_std >= 0 & lag_crime >= 0 & p_value <= 0.05 ~ "High-High",
      crime_std <= 0 & lag_crime <= 0 & p_value <= 0.05 ~ "Low-Low",
      crime_std >= 0 & lag_crime <= 0 & p_value <= 0.05 ~ "High-Low",
      crime_std <= 0 & lag_crime >= 0 & p_value <= 0.05 ~ "Low-High",
      TRUE ~ "Not significant"
    )
  )

## Visualising LISA cluster maps
cluster_palette <- c(
  "High-High" = "#1a9850",
  "Low-Low" = "#d73027",
  "High-Low" = "#66bd63",
  "Low-High" = "#f46d43",
  "Not significant" = "grey80"
)

# Map 1: Greenspace clusters
map_green <- ggplot(greenspace_sf) +
  geom_sf(aes(fill = cluster_type), color = "white", size = 0.1) +
  scale_fill_manual(values = cluster_palette) +
  labs(title = "LISA: Green Space Change (2017–2024)") +
  theme_void() +
  theme(legend.position = "none")

# Map 2: Crime rate clusters
map_crime <- ggplot(crime_clean) +
  geom_sf(aes(fill = crime_cluster), color = "white", size = 0.1) +
  scale_fill_manual(values = cluster_palette) +
  labs(title = "LISA: Crime Rate Change (2017–2024)") +
  theme_void() +
  theme(legend.position = "none")

# Combine both maps side-by-side
map_green + map_crime

## Cross-tabulating green space vs crime clusters
cluster_compare <- crime_clean %>%
  st_drop_geometry() %>%
  select(lsoa21cd, crime_cluster) %>%
  left_join(
    greenspace_sf %>%
      st_drop_geometry() %>%
      select(lsoa21cd, green_cluster = cluster_type),
    by = "lsoa21cd"
  )

# Generating and printing cross-tabulation
table(cluster_compare$green_cluster, cluster_compare$crime_cluster)
    
# ====================================
### MATCHING (PSM)
# ====================================

## Loading required libraries
library(dplyr)
library(tidyr)
library(sf)
library(ggplot2)
library(readxl)
library(MatchIt)
library(patchwork)

## Calculating green space change
greenspace_comparison <- greenspace_comparison %>%
  mutate(green_change = green_percent_2024 - green_percent_2017)

# Defining treatment threshold as top decile of greening
treat_threshold <- quantile(greenspace_comparison$green_change, 0.9, na.rm = TRUE)

# Flagging LSOAs as treated, control, or excluded
greenspace_comparison <- greenspace_comparison %>%
  mutate(
    treated = ifelse(green_change >= treat_threshold, 1, 0),
    control = ifelse(green_change <= 0 & treated == 0, 1, 0),
    group = case_when(
      treated == 1 ~ "Treated",
      control == 1 ~ "Control",
      TRUE ~ NA_character_
    )
  )

## Processing and aggregating crime data
crime_panel <- all_crime_data %>%
  filter(Crime.type == "Violence and sexual offences") %>%
  mutate(Year = as.integer(substr(Month, 1, 4))) %>%
  filter(Year >= 2017 & Year <= 2024) %>%
  group_by(LSOA.code, Year) %>%
  summarise(total_crimes = n(), .groups = "drop")

## Reshaping population data for merge
pop_long <- population_full %>%
  rename(LSOA.code = lsoa_code) %>%
  mutate(Year = year) %>%
  select(LSOA.code, Year, population)

## Merging crime, population, and treatment info
crime_data_panel <- crime_panel %>%
  left_join(pop_long, by = c("LSOA.code", "Year")) %>%
  mutate(crime_rate = 1000 * total_crimes / population) %>%
  left_join(
    greenspace_comparison %>%
      select(LSOA.code = lsoa21cd, treated, control, group),
    by = "LSOA.code"
  ) %>%
  filter(group %in% c("Treated", "Control"))

# Plotting trend (unmatched sample)
unmatched_lsoas_plot <- ggplot(crime_data_panel %>% filter(Year >= 2017),
                                aes(x = Year, y = crime_rate, color = group)) +
  stat_summary(fun = mean, geom = "line", size = 1.2) +
  geom_vline(xintercept = 2020.5, linetype = "dashed") +
  annotate("rect", xmin = 2018.5, xmax = 2020.5, ymin = -Inf, ymax = Inf,
           alpha = 0.2, fill = "grey70") +
  geom_vline(xintercept = 2018.5, linetype = "dashed", color = "black") +
  geom_vline(xintercept = 2020.5, linetype = "dashed", color = "black") +
  labs(title = "Unmatched Sample: Treatment vs Control", x = "Year", y = "Violent Crime rate per 1,000 residents", color = "Group") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 22, family = "Times"),
    axis.text = element_text(size = 16, family = "Times")
  )

## Preparing matching dataset (2017–2018 baseline)
crime_baseline <- crime_data_panel %>%
  filter(Year %in% c(2017, 2018)) %>%
  pivot_wider(
    id_cols = LSOA.code,
    names_from = Year,
    values_from = crime_rate,
    names_prefix = "crime_rate_"
  )

# Combining crime, green space, and covariates
match_data <- greenspace_comparison %>%
  filter(group %in% c("Treated", "Control")) %>%
  left_join(crime_baseline, by = c("lsoa21cd" = "LSOA.code")) %>%
  select(
    LSOA_code = lsoa21cd,
    treated,
    group,
    green_percent_2017,
    crime_rate_2017,
    crime_rate_2018,
    imd_score,
    crime_score,
    env_score,
    imd_decile,
    pop_density_2017,
    percent_nonwhite,
    green_change
  ) %>%
  drop_na()

# Running propensity score matching
psm_model <- matchit(
  treated ~ green_percent_2017 + crime_rate_2017 + crime_rate_2018 +
    imd_score + crime_score + env_score + pop_density_2017 + percent_nonwhite,
  data = match_data,
  method = "nearest",
  ratio = 1,
  caliper = 0.6
)

# Extracting matched sample
matched_data <- match.data(psm_model)

# Checking balance summary
summary(psm_model)

## Filtering panel data to matched sample
matched_panel <- crime_data_panel %>%
  filter(LSOA.code %in% matched_data$LSOA_code)

# Plotting trend (matched sample)
matched_lsoas_plot <- ggplot(matched_panel, aes(x = Year, y = crime_rate, color = group)) +
  stat_summary(fun = mean, geom = "line", size = 1.2) +
  geom_vline(xintercept = 2020.5, linetype = "dashed") +
  annotate("rect", xmin = 2018.5, xmax = 2020.5, ymin = -Inf, ymax = Inf,
           alpha = 0.2, fill = "grey70") +
  geom_vline(xintercept = 2018.5, linetype = "dashed", color = "black") +
  geom_vline(xintercept = 2020.5, linetype = "dashed", color = "black") +
  labs(title = "PSM Sample: Treated vs Control", x = "Year", y = "", color = "Group") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 22, family = "Times"),
    axis.text = element_text(size = 16, family = "Times")
  )

# Combining matched and unmatched plots
combined_plot <- unmatched_lsoas_plot + matched_lsoas_plot +
  plot_layout(ncol = 2, widths = c(1, 1), guides = "collect") &
  theme(legend.position = "bottom")

combined_plot <- combined_plot +
  plot_annotation(
    title = "",
    theme = theme(
      plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
      legend.text = element_text(size = 16, hjust = 0.5, family = "Times"),
      legend.title = element_text(size = 16, hjust = 0.5, family = "Times")
    )
  )
combined_plot

# Saving plot
ggsave("combined_trend_plot.png", combined_plot,
       width = 20, height = 9, dpi = 400, bg = "white")

# ====================================
### Placebo DiD
# ====================================

## Creating placebo dataset (pre-treatment years only)
# Using only 2017 and 2018 as pre-treatment period
placebo_data <- matched_panel %>%
  filter(Year %in% c(2017, 2018)) %>%
  mutate(
    # Define placebo post-treatment indicator
    post_placebo = ifelse(Year == 2018, 1, 0)
  )

## Estimating placebo DiD model
# Regressing crime rate on treatment x placebo interaction
placebo_did_model <- lm(
  crime_rate ~ treated * post_placebo,
  data = placebo_data
)

# Viewing placebo DiD model summary
summary(placebo_did_model)

# ====================================
### TABLE 1: Main Models
# ====================================

# Loading required libraries
library(dplyr)
library(tidyr)
library(sf)
library(ggplot2)
library(MatchIt)
library(lmtest)
library(sandwich)
library(nngeo)
library(broom)
library(ggeffects)
library(fixest)
library(kableExtra)
library(purrr)
library(tibble)

## Adding covariates to matched panel
matched_panel <- matched_panel %>%
  left_join(
    match_data %>%
      select(
        LSOA_code,
        green_percent_2017,
        green_change,
        imd_score,
        crime_score,
        env_score,
        imd_decile,
        pop_density_2017,
        percent_nonwhite,
        crime_rate_2017,
        crime_rate_2018
      ),
    by = c("LSOA.code" = "LSOA_code")
  ) %>%
  mutate(post = ifelse(Year >= 2021, 1, 0))  # Treatment begins in 2021

## Model 1: DiD with Covariates
model1 <- lm(
  crime_rate ~ treated * post + green_percent_2017 + crime_rate_2017 + crime_rate_2018 +
    imd_score + crime_score + env_score + pop_density_2017 + percent_nonwhite,
  data = matched_panel
)

## Model 2: DiD with Fixed Effects
model2 <- feols(
  crime_rate ~ treated * post | LSOA.code + Year,
  data = matched_panel,
  cluster = "LSOA.code"
)

## Model 3: Continuous Fixed Effects
model3 <- feols(
  crime_rate ~ green_change * post | LSOA.code + Year,
  cluster = ~LSOA.code,
  data = matched_panel
)

## Model 4: Spillover Effects
# Computing centroids of LSOAs
all_centroids <- st_centroid(lsoa_sf)

# Identifying treated LSOAs
treated_lsoas <- lsoa_sf %>%
  filter(lsoa21cd %in% matched_data$LSOA_code) %>%
  left_join(matched_data %>% select(LSOA_code, treated),
            by = c("lsoa21cd" = "LSOA_code")) %>%
  filter(treated == 1)

# Calculating distances to treated LSOAs
all_centroids <- all_centroids %>%
  mutate(dist_to_treated = st_distance(geometry, st_union(st_geometry(treated_lsoas))) %>%
           as.numeric() / 1000)

# Joining distances to matched panel
matched_panel <- matched_panel %>%
  left_join(
    st_drop_geometry(all_centroids)[, c("lsoa21cd", "dist_to_treated")],
    by = c("LSOA.code" = "lsoa21cd")
  ) %>%
  mutate(
    dist_band = case_when(
      dist_to_treated < 0.5 ~ "within_500m",
      dist_to_treated < 1 ~ "500m_1km",
      dist_to_treated < 2 ~ "1km_2km",
      TRUE ~ "beyond_2km"
    ),
    dist_band = factor(dist_band, levels = c("within_500m", "500m_1km", "1km_2km", "beyond_2km"))
  )

# Estimating DiD with spatial spillover bands
model4 <- feols(
  crime_rate ~ i(dist_band, post, ref = "beyond_2km") + treated * post | LSOA.code + Year,
  cluster = ~LSOA.code,
  data = matched_panel
)

## Model 5: Heterogeneous (by IMD Decile)
matched_panel <- matched_panel %>%
  mutate(imd_decile = as.factor(imd_decile))

model5 <- feols(
  crime_rate ~ i(imd_decile, treated * post, ref = 1) | LSOA.code + Year,
  cluster = ~LSOA.code,
  data = matched_panel
)

## Model 6: Event Study
matched_panel <- matched_panel %>%
  mutate(rel_year = Year - 2021)

model6 <- feols(
  crime_rate ~ i(rel_year, treated, ref = -1) | LSOA.code + Year,
  cluster = ~LSOA.code,
  data = matched_panel
)

## Combining models for custom table
model_list <- list(
  "1. DiD with Controls" = model1,
  "2. DiD with Fixed Effects" = model2,
  "3. Continuous Fixed Effects" = model3,
  "4. Spillover Effects" = model4,
  "5. Heterogeneous (by IMD Decile)" = model5,
  "6. Event Study" = model6
)

## Extracting and formating estimates
tidy_df <- imap_dfr(model_list, function(model, model_name) {
  tidy(model) %>%
    mutate(Model = model_name)
})

remove_vars <- c(
  "green_percent_2017", "crime_rate_2017", "crime_rate_2018",
  "imd_score", "crime_score", "env_score", 
  "pop_density_2017", "percent_nonwhite", "(Intercept)", "treated", "post", 
  "imd_decile::2:treated * post", "imd_decile::3:treated * post", 
  "imd_decile::4:treated * post", "imd_decile::5:treated * post", 
  "rel_year::-4:treated", "rel_year::-3:treated", "rel_year::-2:treated", 
  "rel_year::0:treated", "dist_band::500m_1km:post", "imd_decile::6:treated * post",
  "imd_decile::7:treated * post", "imd_decile::8:treated * post", "rel_year::1:treated"
)

tidy_formatted <- tidy_df %>%
  filter(!term %in% remove_vars) %>%
  mutate(
    term_label = term,
    formatted = sprintf("%.3f%s<br>(%.3f)",
                        estimate,
                        ifelse(p.value < 0.001, "***",
                        ifelse(p.value < 0.01, "**",
                        ifelse(p.value < 0.05, "*", ""))),
                        std.error)
  ) %>%
  select(Model, term_label, formatted)

## Reshaping and cleaning labels
table_data <- tidy_formatted %>%
  pivot_wider(names_from = Model, values_from = formatted)

clean_names <- c(
  "treated:post" = "Treated × Post",
  "green_change:post" = "Green Change × Post",
  "post:near_treated" = "Near Treated Area × Post",
  "dist_band::within_500m:post" = "Within 500m of Treated × Post",
  "dist_band::1km_2km:post" = "1km–2km from Treated × Post",
  "imd_decile::9:treated * post" = "Treated × Post × IMD Decile 9",
  "imd_decile::10:treated * post" = "Treated × Post × IMD Decile 10",
  "rel_year::2:treated" = "Event Study Lead/Lag: Year 2",
  "rel_year::3:treated" = "Event Study Lead/Lag: Year 3"
)

table_data$term_label <- recode(table_data$term_label, !!!clean_names)

table_data[is.na(table_data)] <- ""

## Adding model feature summary
feature_summary <- imap_dfr(model_list, function(model, model_name) {
  terms <- tryCatch({
    if ("fixest" %in% class(model)) {
      all.vars(model$fml_all$linear)
    } else {
      attr(model$terms, "term.labels")
    }
  }, error = function(e) character(0))
  
  terms <- names(coef(model))
  fixef_vars <- model$fixef_vars %||% character(0)
  
  tibble(
    Model = model_name,
    Observations = format(nobs(model), big.mark = ","),
    `LSOA Fixed Effects` = if ("LSOA.code" %in% fixef_vars) "Yes" else "No",
    `Year Fixed Effects` = if ("Year" %in% fixef_vars) "Yes" else "No",
    `Socioeconomic Controls` = if (any(grepl("imd|nonwhite|pop_density", terms))) "Yes" else "No",
    `Environmental Controls` = if (any(grepl("green_percent|crime_score|env_score", terms))) "Yes" else "No"
  )
}) %>%
  pivot_longer(-Model, names_to = "Term", values_to = "value") %>%
  pivot_wider(names_from = Model, values_from = value)

# Combining estimates and features
table_full <- bind_rows(
  table_data %>% rename(Term = term_label),
  feature_summary %>% mutate(row_type = ifelse(Term == "Observations", "Observations", "Control"))
)

table_full <- table_full %>%
  mutate(
    row_type = case_when(
      Term == "Observations" ~ "Observations",
      Term %in% c("LSOA Fixed Effects", "Year Fixed Effects",
                  "Socioeconomic Controls", "Environmental Controls") ~ "Control",
      TRUE ~ "Main"
    )
  )

## Building and saving custom html table
table_html <- kable(table_full %>% select(-row_type), format = "html", escape = FALSE,
                    col.names = c("", names(model_list))) %>%
  kable_styling(
    bootstrap_options = c("striped", "condensed", "responsive"),
    full_width = FALSE,
    font_size = 14,
    position = "center"
  ) %>%
  add_header_above(c("Main Models" = ncol(table_full) - 1), bold = FALSE) %>%
  row_spec(0, bold = FALSE, extra_css = "font-weight: normal;") %>%
  row_spec(
    which(table_full$row_type == "Control")[1],
    bold = FALSE,
    extra_css = "border-top: 1px solid;"
  ) %>%
  footnote(
    general = "Standard errors in parentheses. All regressions are clustered at LSOA level. *** p < 0.001; ** p < 0.01; * p < 0.05.",
    general_title = ""
  )

table_html

save_kable(table_html, file = "main_models.html")

# ====================================
### TABLES 2 AND 3: SDM
# ====================================

## Loading required libraries
library(sf)
library(spdep)
library(spatialreg)
library(dplyr)
library(broom)
library(tidyr)
library(kableExtra)
library(purrr)
library(tibble)

## Preparing spatial dataset (matched units only)
spatial_data <- lsoa_sf %>%
  left_join(matched_panel, by = c("lsoa21cd" = "LSOA.code")) %>%
  filter(
    !is.na(crime_rate),
    !is.na(treated),
    !is.na(green_percent_2017),
    !is.na(imd_score),
    !is.na(pop_density_2017),
    !is.na(green_change)
  )

## Creating spatial neighbors (within 1500m)
centroids <- st_centroid(spatial_data)
coords <- st_coordinates(centroids)

nb_dist <- dnearneigh(coords, d1 = 0, d2 = 1500)

# Dropping isolated units with no neighbors
isolated <- which(card(nb_dist) == 0)
if (length(isolated) > 0) {
  cat("Dropping", length(isolated), "isolated units with no neighbors.\n")
  spatial_data <- spatial_data[-isolated, ]
  coords <- coords[-isolated, ]
  nb_dist <- dnearneigh(coords, d1 = 0, d2 = 1500)
}

# Spatial weights matrix
lw_dist <- nb2listw(nb_dist, style = "W", zero.policy = TRUE)

## Converting to object for spatialreg
sdm_sp <- as_Spatial(spatial_data)

## Estimating Spatial Durbin Model (SDM)
sdm_model_dist <- lagsarlm(
  crime_rate ~ green_percent_2017 + green_change + imd_score + pop_density_2017,
  data = sdm_sp@data,
  listw = lw_dist,
  type = "mixed",   # Spatial Durbin Model
  zero.policy = TRUE
)

## Summarising model and computing impacts
summary(sdm_model_dist)

impacts_sdm <- impacts(sdm_model_dist, listw = lw_dist, R = 1000)
impacts_summary <- summary(impacts_sdm, zstats = TRUE)

## Formating SDM model output for html table
spatial_model_list <- list(
  "7. SDM Model" = sdm_model_dist
)

spatial_tidy_df <- imap_dfr(spatial_model_list, function(model, model_name) {
  tidy(model) %>%
    mutate(Model = model_name)
})

spatial_tidy_formatted <- spatial_tidy_df %>%
  filter(!term %in% c("(Intercept)", "pop_density_2017", "lag.pop_density_2017")) %>%
  mutate(
    term_label = term,
    formatted = sprintf("%.3f%s<br>(%.3f)",
                        estimate,
                        ifelse(p.value < 0.001, "***",
                        ifelse(p.value < 0.01, "**",
                        ifelse(p.value < 0.05, "*", ""))),
                        std.error)
  ) %>%
  select(Model, term_label, formatted)

spatial_table_data <- spatial_tidy_formatted %>%
  pivot_wider(names_from = Model, values_from = formatted)

# Label cleanup
spatial_clean_names <- c(
  "treated" = "Treated",
  "green_percent_2017" = "Green Coverage (2017)",
  "green_change" = "Green Change (2017–2024)",
  "imd_score" = "IMD Score",
  "lag.treated" = "Lagged: Treated",
  "lag.green_percent_2017" = "Lagged: Green Coverage",
  "lag.green_change" = "Lagged: Green Change",
  "lag.imd_score" = "Lagged: IMD Score"
)

spatial_table_data$term_label <- recode(spatial_table_data$term_label, !!!spatial_clean_names)
spatial_table_data[is.na(spatial_table_data)] <- ""

## Adding summary information
spatial_feature_summary <- imap_dfr(spatial_model_list, function(model, model_name) {
  terms <- names(coef(model))
  tibble(
    Model = model_name,
    Observations = format(nrow(model$X), big.mark = ","),
    `Spatial Lag` = if (any(grepl("^lag\\.", terms))) "Yes" else "No",
    `Socioeconomic Controls` = if (any(grepl("imd_|pop_density", terms))) "Yes" else "No",
    `Environmental Controls` = if (any(grepl("green_percent", terms))) "Yes" else "No"
  )
}) %>%
  pivot_longer(-Model, names_to = "Term", values_to = "value") %>%
  pivot_wider(names_from = Model, values_from = value)

## Combining coefficients and features
spatial_table_full <- bind_rows(
  spatial_table_data %>% rename(Term = term_label),
  spatial_feature_summary %>% mutate(row_type = ifelse(Term == "Observations", "Observations", "Control"))
) %>%
  mutate(
    row_type = case_when(
      Term == "Observations" ~ "Observations",
      Term %in% c("Spatial Lag", "Socioeconomic Controls", "Environmental Controls") ~ "Control",
      TRUE ~ "Main"
    )
  )

## Rendering and saving html table
spatial_table_html <- kable(spatial_table_full %>% select(-row_type), format = "html", escape = FALSE,
                            col.names = c("", names(spatial_model_list))) %>%
  kable_styling(
    bootstrap_options = c("striped", "condensed", "responsive"),
    full_width = FALSE,
    font_size = 14,
    position = "center"
  ) %>%
  add_header_above(c("Spatial Durbin Model (SDM)" = ncol(spatial_table_full) - 1), bold = FALSE) %>%
  row_spec(0, bold = FALSE, extra_css = "font-weight: normal;") %>%
  row_spec(
    which(spatial_table_full$row_type == "Control")[1],
    bold = FALSE,
    extra_css = "border-top: 1px solid;"
  ) %>%
  footnote(
    general = "Standard errors in parentheses. *** p < 0.001; ** p < 0.01; * p < 0.05."
  )

spatial_table_html

save_kable(spatial_table_html, file = "spatial_models.html")

## Decomposed SDM effects table
variables <- c("green_percent_2017", "green_change", "imd_score")

direct_est   <- impacts_summary$res$direct[1:3]
indirect_est <- impacts_summary$res$indirect[1:3]
total_est    <- impacts_summary$res$total[1:3]

direct_se    <- apply(impacts_summary$sres$direct[, variables], 2, sd)
indirect_se  <- apply(impacts_summary$sres$indirect[, variables], 2, sd)
total_se     <- apply(impacts_summary$sres$total[, variables], 2, sd)

direct_p     <- impacts_summary$pzmat[variables, "Direct"]
indirect_p   <- impacts_summary$pzmat[variables, "Indirect"]
total_p      <- impacts_summary$pzmat[variables, "Total"]

# label cleanup
term_labels <- recode(variables,
  "green_percent_2017" = "Green Coverage (2017)",
  "green_change" = "Green Change (2017–2024)",
  "imd_score" = "IMD Score"
)

# Formatting estimates
format_effect <- function(est, se, p) {
  stars <- ifelse(p < 0.001, "***",
           ifelse(p < 0.01, "**",
           ifelse(p < 0.05, "*", "")))
  sprintf("%.3f%s<br>(%.3f)", est, stars, se)
}

# Building effect summary table
impact_table <- tibble::tibble(
  Term = term_labels,
  `Direct Effect`   = format_effect(direct_est, direct_se, direct_p),
  `Indirect Effect` = format_effect(indirect_est, indirect_se, indirect_p),
  `Total Effect`    = format_effect(total_est, total_se, total_p)
)

# Rendering and saving html table
spatial_models_demcomposed_effects_html <- kable(impact_table, format = "html", escape = FALSE,
      col.names = c("Variable", "Direct", "Indirect", "Total")) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = FALSE, font_size = 14) %>%
  add_header_above(c("SDM−Decomposed Effects" = 4), bold = FALSE) %>%
  footnote(
    general = "Standard errors in parentheses. *** p < 0.001; ** p < 0.01; * p < 0.05."
  )

spatial_models_demcomposed_effects_html

save_kable(spatial_models_demcomposed_effects_html, file = "spatial_models_demcomposed_effects.html")

# ====================================
### FIGURE 1
# ====================================

## Loading required libraries
library(ggplot2)
library(dplyr)
library(sf)
library(cowplot)
library(patchwork)
library(tidyr)
library(grid)

## Preparing green space change data
greenspace_diff <- lsoa_sf %>%
  select(lsoa21cd, geometry) %>%
  left_join(greenspace_comparison, by = "lsoa21cd") %>%
  mutate(
    diff = green_percent_2024 - green_percent_2017,
    diff_vis = sign(diff) * sqrt(abs(diff))  # Transform for visual contrast
  )

# Computing shared visual limits (min/max for gradient)
shared_diff_vis_limits <- range(greenspace_diff$diff_vis, na.rm = TRUE)

# Defining boroughs to highlight
highlight_boroughs <- c("")  # No boroughs specified
highlight_borders <- boroughs %>%
  filter(DIST_NAME %in% highlight_boroughs)

break_vals <- c(-20, -10, 0, 10, 20, 40)

# Function to generate green space change map
main_diff_map <- function(data, show_legend = FALSE) {
  ggplot(data %>% filter(!is.na(diff_vis))) +
    geom_sf(aes(fill = diff_vis), color = "grey70", size = 0.05) +
    geom_sf(data = highlight_borders, fill = NA, color = "black", linewidth = 0.8) +
    scale_fill_gradient2(
      low = "firebrick2",
      mid = "white",
      high = "forestgreen",
      midpoint = 0,
      limits = shared_diff_vis_limits,
      name = "",
      breaks = sign(break_vals) * sqrt(abs(break_vals)),
      labels = paste0(break_vals, "%")
    ) +
    labs(title = "") +
    theme_void(base_size = 14) +
    theme(
      plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
      legend.position = ifelse(show_legend, "right", "none"),
      legend.direction = "horizontal",
      legend.key.width = unit(2, "cm"),
      legend.key.height = unit(0.5, "cm"),
      legend.title = element_text(size = 20, family = "Times"),
      legend.text = element_text(size = 18, family = "Times"),
      plot.caption = element_text(hjust = 0.5, size = 10, margin = margin(t = 6))
    )
}

## Create Main Greenspace Change Map (no legend)
main_diff <- main_diff_map(greenspace_diff)

## Using Main Plot as Layout (no inset)
layout_diff <- main_diff

## Extracting legend from separate plot
legend_diff_plot <- main_diff_map(greenspace_diff, show_legend = TRUE)
legend_diff <- get_legend(legend_diff_plot)

## Creating caption
caption_text <- ggdraw() +
  draw_label(
    "",  # Add text here if desired
    x = 0.5, hjust = 0.5, size = 10,
    fontface = "plain"
  )

## Stack mapping and legend
map_and_legend <- plot_grid(
  layout_diff,
  legend_diff,
  ncol = 1,
  rel_heights = c(1, 0.06)
)

## Stacking caption below map + legend
final_plot_diff <- plot_grid(
  map_and_legend,
  caption_text,
  ncol = 1,
  rel_heights = c(1, 0.04)
)

## Displaying and saving to file
final_plot_diff

ggsave(
  "final_greenspace_change_map2.png",
  final_plot_diff,
  width = 16,
  height = 9,
  dpi = 400,
  bg = "white"
)

ggsave("final_greenspace_change_map2.png", final_plot_diff, width = 16, height = 9, dpi = 400, bg = "white")

# ====================================
### FIGURE 2
# ====================================

## Combining wards with canopy and priority data
wards_combined <- wards %>%
  left_join(canopy_data, by = "GSS_CODE") %>%
  mutate(
    # Converting ranks to numeric
    `Tree Canopy Rank` = as.numeric(`Tree Canopy Rank`),
    UHItempRank = as.numeric(UHItempRank),
    IMDrank = as.numeric(IMDrank),
    `Green/Blue Cover (Curio)` = as.numeric(`Green/Blue Cover (Curio)`),
    PM25Rank = as.numeric(PM25Rank),
    N02Rank = as.numeric(N02Rank),
    SINCRanknew = as.numeric(SINCRanknew),

    # Creating binary flags
    canopy_priority = `Tree Canopy Rank` <= 200,
    deprivation_priority = IMDrank <= 75,
    heat_priority = UHItempRank <= 200,
    air_quality_priority = PM25Rank <= 250 | N02Rank <= 250,
    nature_gap = SINCRanknew <= 300,
    feasible = `Green/Blue Cover (Curio)` > 30 & `Green/Blue Cover (Curio)` < 80,

    # Calculating composite priority score and assigning bands
    priority_score = canopy_priority + deprivation_priority + heat_priority +
                     air_quality_priority + nature_gap,
    priority_band = case_when(
      priority_score >= 3 ~ "High",
      priority_score == 2 ~ "Moderate",
      TRUE ~ "Low"
    ),

    # Flagging high-priority feasible areas
    high_priority = feasible & priority_score >= 2
  )

## Spatially join LSOAs to high-priority wards
lsoa_with_priority <- st_transform(lsoa_sf, st_crs(wards_combined)) %>%
  mutate(centroid = st_centroid(geometry)) %>%
  st_set_geometry("centroid") %>%
  st_join(wards_combined %>% select(high_priority, priority_band), left = TRUE) %>%
  st_set_geometry("geometry") %>%
  group_by(lsoa21cd) %>%
  slice(1) %>%
  ungroup()

## Highlighting top decile of greening by priority band
greenspace_all <- greenspace_change %>%
  mutate(
    substantial_greening = green_change >= quantile(green_change, 0.9, na.rm = TRUE),
    plot_band = ifelse(substantial_greening, priority_band, "No Greening"),
    plot_band = factor(plot_band, levels = c("High", "Moderate", "Low", "No Greening"))
  )

fill_colors <- c(
  "High" = "forestgreen",
  "Moderate" = "mediumseagreen",
  "Low" = "darkseagreen3",
  "No Greening" = "grey90"
)

priority_band_greening <- ggplot(greenspace_all) +
  geom_sf(aes(fill = plot_band), color = "white", size = 0.1) +
  scale_fill_manual(
    values = fill_colors,
    name = ""
  ) +
  theme_void(base_size = 14) +
  labs(
    title = "",
    caption = ""
  ) + 
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    plot.caption = element_text(hjust = 0.5),
    legend.position = "bottom",
    legend.title = element_text(size = 20, family = "Times"),
    legend.text = element_text(size = 18, family = "Times"),
    legend.margin = margin(t = 10), # adds spacing between map and legend
    plot.margin = margin(10, 10, 10, 10)
  ) +
  guides(fill = guide_legend(
    title.position = "top",
    title.hjust = 0.5,
    nrow = 1
  ))
priority_band_greening

ggsave("priority_band_greening.png", priority_band_greening,
       width = 16, height = 9, dpi = 400, bg = "white")

# ====================================
### FIGURE 3
# ====================================

## Loading required libraries
library(dplyr)
library(tidyr)
library(stringr)
library(sf)
library(ggplot2)
library(cowplot)

## Aggregating violent crimes by year and LSOA
crime_summary <- all_crime_data %>%
  filter(Crime.type == "Violence and sexual offences") %>%
  mutate(Year = as.integer(str_sub(Month, 1, 4))) %>%
  filter(Year %in% c(2017, 2024)) %>%
  filter(!is.na(LSOA.code) & str_detect(LSOA.code, "^E01")) %>%  # Valid LSOA codes only
  group_by(LSOA.code, Year) %>%
  summarise(total_crimes = n(), .groups = "drop") %>%
  pivot_wider(
    names_from = Year,
    values_from = total_crimes,
    names_prefix = "crime_"
  ) %>%
  mutate(across(starts_with("crime_"), ~replace_na(., 0)))

## Joining with population data and compute rate change
pop_subset <- population_full %>%
  filter(year %in% c(2017, 2024)) %>%
  select(lsoa_code, year, Total) %>%
  pivot_wider(
    names_from = year,
    values_from = Total,
    names_prefix = "pop_"
  )

crime_rates <- crime_summary %>%
  left_join(pop_subset, by = c("LSOA.code" = "lsoa_code")) %>%
  mutate(
    rate_2017 = 1000 * crime_2017 / pop_2017,
    rate_2024 = 1000 * crime_2024 / pop_2024,
    delta_crime_rate = rate_2024 - rate_2017
  ) %>%
  select(LSOA.code, delta_crime_rate)

## Merging with LSOA polygons and green space change
bivar_sf <- lsoa_sf %>%
  select(lsoa21cd, geometry) %>%
  left_join(crime_rates, by = c("lsoa21cd" = "LSOA.code")) %>%
  left_join(greenspace_comparison, by = "lsoa21cd") %>%
  mutate(
    green_change = green_percent_2024 - green_percent_2017
  )

## Binning green and crime change into terciles
bivar_sf <- bivar_sf %>%
  mutate(
    crime_bin = ntile(delta_crime_rate, 3),
    green_bin = ntile(green_change, 3),
    bivar_class = paste0(green_bin, "-", crime_bin)
  )

## Defining intuitive bivariate color palette
bivar_palette_intuitive <- c(
  "1-1" = "#fddbc7",  # ↓ green, ↓ crime — weak win
  "2-1" = "#d9f0d3",  # neutral green, ↓ crime
  "3-1" = "#228B22",  # ↑ green, ↓ crime — strong win
  "1-2" = "#f4cccc",  # ↓ green, stable crime
  "2-2" = "#e0e0e0",  # neutral both
  "3-2" = "#a6dba0",  # ↑ green, stable crime
  "1-3" = "#B2182B",  # ↓ green, ↑ crime — strong fail
  "2-3" = "#f4a582",  # neutral green, ↑ crime
  "3-3" = "#d1e5f0"   # ↑ green, ↑ crime — ambiguous
)

## Creating main map (no highlighted boroughs)
highlight_boroughs <- c("")  # No boroughs selected
highlight_borders <- boroughs %>%
  filter(DIST_NAME %in% highlight_boroughs)

final_bivar_plot <- ggplot(bivar_sf %>% filter(!is.na(bivar_class))) +
  geom_sf(aes(fill = bivar_class), color = "white", size = 0.05) +
  geom_sf(data = highlight_borders, fill = NA, color = "black", linewidth = 0.8) +
  scale_fill_manual(
    values = bivar_palette_intuitive,
    name = NULL,
    guide = "none"
  ) +
  labs(
    title = "",
    caption = ""
  ) +
  theme_void(base_size = 13) +
  theme(
    plot.margin = margin(5, -10, 5, 5),
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.caption = element_text(hjust = 0.5, size = 10)
  )

## Building legend as a 3x3 tile grid
legend_data <- expand.grid(
  green_bin = 1:3,
  crime_bin = 1:3
) %>%
  mutate(
    bivar_class = paste0(green_bin, "-", crime_bin),
    fill_color = bivar_palette_intuitive[bivar_class],
    x = green_bin,
    y = 4 - crime_bin  # Flip Y for visual logic
  )

legend_tile <- ggplot(legend_data, aes(x = x, y = y)) +
  geom_tile(aes(fill = fill_color), color = "white") +
  scale_fill_identity() +
  scale_x_continuous(
    breaks = 1:3,
    labels = c("Less", "Neutral", "More"),
    expand = c(0, 0)
  ) +
  scale_y_continuous(
    breaks = 1:3,
    labels = c("More", "Neutral", "Less"),
    expand = c(0, 0)
  ) +
  coord_fixed(ratio = 1.5) +
  labs(
    x = "Greenspace Change",
    y = "Crime Rate Change"
  ) +
  theme_minimal(base_size = 8) +
  theme(
    axis.title = element_text(face = "bold", size = 10, family = "Times"),
    axis.text = element_text(size = 9, family = "Times"),
    panel.grid = element_blank(),
    plot.margin = margin(5, 10, 5, -40),
    plot.background = element_rect(fill = "white", color = NA)
  )

## Combining map and legend into one plot
combined_plot <- plot_grid(
  final_bivar_plot,
  legend_tile,
  ncol = 2,
  rel_widths = c(0.9, 0.1)
)
combined_plot

## Saving plot
ggsave("bivariate_map_green_crime.png", combined_plot, width = 14, height = 8, dpi = 300, bg = "white")

# ====================================
### ROBUSTNESS CHECKS
# ====================================

## Loading necessary libraries
library(fixest)
library(dplyr)
library(sf)

## Joining borough information to matched panel
# Adding borough names from spatial layer
matched_panel <- matched_panel %>%
  left_join(
    lsoa_sf %>% st_drop_geometry() %>% select(lsoa21cd, lad22nm),
    by = c("LSOA.code" = "lsoa21cd")
  ) %>%
  rename(borough = lad22nm)

## Borough-clustered standard errors
# DiD with Fixed Effects clustered at borough level
model3_borough <- feols(
  crime_rate ~ treated * post | LSOA.code + Year,
  cluster = ~borough,
  data = matched_panel
)

# Continuous DiD with borough clustering
model4_borough <- feols(
  crime_rate ~ green_change * post | LSOA.code + Year,
  cluster = ~borough,
  data = matched_panel
)

# Displaying comparison of default vs borough-clustered models
etable(
  model2, model3_borough, model3, model4_borough,
  dict = c(
    "treated:post" = "Treated × Post",
    "green_change:post" = "Green Change × Post"
  )
)

## Preparing coordinates for Conley (1999) standard errors
# Transforming LSOA geometries to WGS84 (longitude/latitude)
lsoa_sf_geo <- st_transform(lsoa_sf, crs = 4326)

# Extracting centroid coordinates
coords <- st_centroid(lsoa_sf_geo) %>%
  st_coordinates() %>%
  as.data.frame() %>%
  bind_cols(lsoa_sf_geo %>% st_drop_geometry() %>% select(lsoa21cd)) %>%
  rename(lon = X, lat = Y)

# Cleaning previous lat/lon from matched_panel if present
matched_panel <- matched_panel %>% select(-matches("^lat$|^lon$|^lat\\.|^lon\\."))

# Adding coordinates to matched panel for spatial standard errors
matched_panel <- matched_panel %>%
  left_join(coords, by = c("LSOA.code" = "lsoa21cd"))

## Estimating model with Conley (1999) standard errors
# Running DiD with fixed effects
model_conley <- feols(
  crime_rate ~ treated * post | LSOA.code + Year,
  data = matched_panel
)

# Computing standard errors with 10km cutoff
se_conley <- vcov_conley(
  model_conley,
  lat = ~lat,
  lon = ~lon,
  cutoff = 10  # in kilometers
)

# Displaying original vs Conley-adjusted results
etable(
  list("Standard Clustered SEs" = model2, "Conley SEs (10km)" = model_conley),
  vcov = list("Standard Clustered SEs" = "cluster", "Conley SEs (10km)" = se_conley),
  dict = c("treated:post" = "Treated × Post")
)
